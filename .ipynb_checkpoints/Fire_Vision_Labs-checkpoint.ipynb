{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "GCS_OUTPUT = 'gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-dataset-7/'  # prefix for output file names\n",
    "\n",
    "TARGET_SIZE = [224, 224]\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "\n",
    "        # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),  # one bytestring\n",
    "        \"size\": tf.io.FixedLenFeature([2], tf.int64),  # two integers\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32)  # a certain number of floats\n",
    "    }\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "\n",
    "    # FixedLenFeature fields are now ready to use: exmple['size']\n",
    "    # VarLenFeature fields require additional sparse_to_dense decoding\n",
    "\n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.reshape(image, [*TARGET_SIZE, 3])\n",
    "\n",
    "    class_num = example['class']\n",
    "\n",
    "    label = example['label']\n",
    "    height = example['size'][0]\n",
    "    width = example['size'][1]\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# read from TFRecords. For optimal performance, read from multiple\n",
    "# TFRecord files at once and set the option experimental_deterministic = False\n",
    "# to allow order-altering optimizations.\n",
    "\n",
    "option_no_order = tf.data.Options()\n",
    "option_no_order.experimental_deterministic = False\n",
    "\n",
    "filenames = tf.io.gfile.glob(GCS_OUTPUT + \"*.tfrec\")\n",
    "dataset4 = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "dataset4 = dataset4.with_options(option_no_order)\n",
    "dataset4 = dataset4.map(read_tfrecord, num_parallel_calls=AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: ((256, 256, 3), (), (), (), (), (None,)), types: (tf.uint8, tf.int64, tf.string, tf.int64, tf.int64, tf.float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, class_num, label, height, width, one_hot_class in dataset4.take(50):\n",
    "    print(\"Image shape {}, {}x{} px, class={} ({:>10}, {})\".format(image.numpy().shape, width, height, class_num,label.numpy().decode('utf8'),one_hot_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "CLASSES = ['Fire', 'Normal']\n",
    "\n",
    "def dataset_to_numpy_util(dataset, N):\n",
    "    dataset = dataset.batch(N)\n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy()\n",
    "        break;  \n",
    "    return numpy_images, numpy_labels\n",
    "'''\n",
    "def title_from_label_and_target(label, correct_label):\n",
    "    label = np.argmax(label, axis=-1)  # one-hot to class number\n",
    "    correct_label = np.argmax(correct_label, axis=-1) # one-hot to class number\n",
    "    correct = (label == correct_label)\n",
    "    return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n",
    "                                CLASSES[correct_label] if not correct else ''), correct\n",
    "'''\n",
    "def display_one_flower(image, title, subplot, red=False):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
    "    return subplot+1\n",
    "  \n",
    "def display_9_images_from_dataset(dataset):\n",
    "    subplot=331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    images, labels = dataset_to_numpy_util(dataset, 9)\n",
    "    for i, image in enumerate(images):\n",
    "        title = CLASSES[np.argmax(labels[i], axis=-1)]\n",
    "        subplot = display_one_flower(image, title, subplot)\n",
    "        if i >= 8:\n",
    "            break;\n",
    "              \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()  \n",
    "\n",
    "    '''\n",
    "def display_9_images_with_predictions(images, predictions, labels):\n",
    "    subplot=331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    for i, image in enumerate(images):\n",
    "        title, correct = title_from_label_and_target(predictions[i], labels[i])\n",
    "        subplot = display_one_flower(image, title, subplot, not correct)\n",
    "        if i >= 8:\n",
    "            break;\n",
    "              \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.set_facecolor('#F8F8F8')\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    #ax.set_ylim(0.28,1.05)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_9_images_from_dataset(dataset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "CLASSES = ['Fire', 'Normal']\n",
    "\n",
    "def show_batch(numpy_images, numpy_labels):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(numpy_images[n])\n",
    "        plt.title(CLASSES[numpy_labels[n]==1][0].title())\n",
    "        plt.axis('off')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_numpy_util(dataset4,N):\n",
    "    dataset = dataset4.batch(N)\n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy() \n",
    "        show_batch(numpy_images, numpy_labels)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_numpy_util(dataset4,50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TF_CONFIG environment variable: {'environment': 'cloud', 'cluster': {}, 'job': {'args': ['--output_dir=/home/jupyter/FYP_FIRENET/fire-eye_trained', '--train_steps=10', '--learning_rate=0.01', '--batch_size=20', '--train_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-dataset-*/', '--eval_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-aug_dataset-9/'], 'job_name': 'Trainer.Task'}, 'task': {}}\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/jupyter/FYP_FIRENET/fire-eye_trained/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "2020-05-21 08:53:20.945920: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2020-05-21 08:53:20.946242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55679fe37c20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-05-21 08:53:20.946287: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-05-21 08:53:20.946483: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jupyter/FYP_FIRENET/Trainer/Task.py\", line 130, in <module>\n",
      "    model.train_and_evaluate(output_dir, hparams)\n",
      "  File \"/home/jupyter/FYP_FIRENET/Trainer/model.py\", line 89, in train_and_evaluate\n",
      "    max_steps=hparams[\"train_steps\"])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 158, in __new__\n",
      "    _validate_input_fn(input_fn)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 53, in _validate_input_fn\n",
      "    raise TypeError('`input_fn` must be callable, given: {}'.format(input_fn))\n",
      "TypeError: `input_fn` must be callable, given: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f950871fe50>\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'rm -rf Trainer.tar.gz fire-eye_trained\\ngcloud ai-platform local train \\\\\\n    --module-name=Trainer.Task \\\\\\n    --package-path=${PWD}/Trainer \\\\\\n    -- \\\\\\n    --output_dir=${PWD}/fire-eye_trained \\\\\\n    --train_steps=10 \\\\\\n    --learning_rate=0.01 \\\\\\n    --batch_size=20 \\\\\\n    --train_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-dataset-*/ \\\\\\n    --eval_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-aug_dataset-9/\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-287bba4cf9e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rm -rf Trainer.tar.gz fire-eye_trained\\ngcloud ai-platform local train \\\\\\n    --module-name=Trainer.Task \\\\\\n    --package-path=${PWD}/Trainer \\\\\\n    -- \\\\\\n    --output_dir=${PWD}/fire-eye_trained \\\\\\n    --train_steps=10 \\\\\\n    --learning_rate=0.01 \\\\\\n    --batch_size=20 \\\\\\n    --train_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-dataset-*/ \\\\\\n    --eval_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-aug_dataset-9/\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'rm -rf Trainer.tar.gz fire-eye_trained\\ngcloud ai-platform local train \\\\\\n    --module-name=Trainer.Task \\\\\\n    --package-path=${PWD}/Trainer \\\\\\n    -- \\\\\\n    --output_dir=${PWD}/fire-eye_trained \\\\\\n    --train_steps=10 \\\\\\n    --learning_rate=0.01 \\\\\\n    --batch_size=20 \\\\\\n    --train_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-dataset-*/ \\\\\\n    --eval_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-aug_dataset-9/\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf Trainer.tar.gz fire-eye_trained\n",
    "gcloud ai-platform local train \\\n",
    "    --module-name=Trainer.Task \\\n",
    "    --package-path=${PWD}/Trainer \\\n",
    "    -- \\\n",
    "    --output_dir=${PWD}/fire-eye_trained \\\n",
    "    --train_steps=10 \\\n",
    "    --learning_rate=0.01 \\\n",
    "    --batch_size=20 \\\n",
    "    --train_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-dataset-*/ \\\n",
    "    --eval_data_path=gs://cloudfire_lyrical-edition-273206/fire_dataset/tfrecords-aug_dataset-9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
